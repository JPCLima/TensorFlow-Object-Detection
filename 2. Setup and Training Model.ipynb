{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "On this section is focus to create a model to detect the different classes.\n",
    "\n",
    "Steps to create and evaluate the  model: \n",
    "1. Setup  \n",
    "\n",
    "    1.1. Setup Paths  \n",
    "    1.2. Get Pretrained Models  \n",
    "    1.3. Create Label Map  \n",
    "    1.4. Create TensorFlow records  \n",
    "    1.5. Copy Model config to Training Folder  \n",
    "    1.6. Update config for Transfer Learning\n",
    "    \n",
    "    \n",
    "2. Train the Model\n",
    "3. Evaluate the model\n",
    "4. Freezing the Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "* Define the path of the directories and file\n",
    "* Download TF Object Detection\n",
    "* Create label Map\n",
    "* Create TF records\n",
    "* Update config file for the transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup Paths\n",
    "\n",
    "Setting up constants:\n",
    "* Model name\n",
    "* Pretrained Model name\n",
    "* [Pretrained Model url](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n",
    "* TODO: change name of script name\n",
    "* Label map name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run in Google Colab\n",
    "\n",
    "Load the the [repository](https://github.com/JPCLima/TensorFlow-Object-Detection) to the [Google Colab](https://colab.research.google.com/notebooks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:46:07.073659Z",
     "start_time": "2021-09-09T20:46:07.065642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Name\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_v13'\n",
    "\n",
    "# Pretrained model name\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# Define labels\n",
    "labels = ['Pepsi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting paths: \n",
    "* Workspace\n",
    "* Scripts\n",
    "* API Model Name\n",
    "* Annotation\n",
    "* Image\n",
    "* Model\n",
    "* Pretrained model\n",
    "* Checkpoint\n",
    "* Output\n",
    "* Protoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:46:15.371696Z",
     "start_time": "2021-09-09T20:46:15.331833Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Paths\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),   \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }\n",
    "\n",
    "# Create all the paths from paths dictionary\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Download the TFOD utils\n",
    "\n",
    "Clone the repo TFOD utils. From this repo we will have access to:\n",
    "\n",
    "* Generate tf records\n",
    "* Update config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T18:03:24.160362Z",
     "start_time": "2021-09-09T18:03:24.145418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define files for the scripts & labelmap\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'generate_tfrecord.py'),\n",
    "    'LABELMAP_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'generate_labelmap.py'), \n",
    "    'UPDATE_CONFIG_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'update_config_file.py'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], 'label_map.pbtxt')\n",
    "}\n",
    "\n",
    "# Clone repo for utils\n",
    "if not any(os.scandir(paths['SCRIPTS_PATH'])):\n",
    "    !git clone https://github.com/JPCLima/TFOD-utils {paths['SCRIPTS_PATH']}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Get Pretrained Models\n",
    "\n",
    "* Download the [TensorFlow Model Garden](https://github.com/tensorflow/models) from github\n",
    "* Install Tensorflow Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T18:05:29.080245Z",
     "start_time": "2021-09-09T18:03:25.764041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get wget to download files\n",
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget\n",
    "\n",
    "# Download models and save them on the APIMODEL_PATH \n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install **TensorFlow Object Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T18:06:03.767536Z",
     "start_time": "2021-09-09T18:06:00.174613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to verify if all the dependencies are correctly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T18:06:11.131961Z",
     "start_time": "2021-09-09T18:06:11.117965Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T18:06:15.807461Z",
     "start_time": "2021-09-09T18:06:12.861936Z"
    }
   },
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T17:27:08.111312Z",
     "start_time": "2021-05-08T17:27:08.097349Z"
    }
   },
   "source": [
    "Install extra dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T17:48:49.523978Z",
     "start_time": "2021-09-09T17:45:50.134228Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade\n",
    "!pip install PyYAML\n",
    "!pip install pytz\n",
    "!pip install tensorflow-gpu\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if object detection can be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:46:38.946122Z",
     "start_time": "2021-09-09T20:46:38.925998Z"
    }
   },
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and import **Pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T11:32:33.687693Z",
     "start_time": "2021-09-08T11:32:32.042908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Create Label Map\n",
    "\n",
    "Creating the label map. \n",
    "* The label names must to be the same as the label from the xml file \n",
    "* Each of the classes must to have unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T11:32:35.839059Z",
     "start_time": "2021-09-08T11:32:35.716676Z"
    }
   },
   "outputs": [],
   "source": [
    "!python {files['LABELMAP_SCRIPT']} -l Pepsi -p {files['LABELMAP']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.5. Create TensorFlow records\n",
    "\n",
    "Import the *archive.tar.gz* to **GOOGLE COLAB** under *Tensorflow\\workspace\\images*\n",
    "\n",
    "\n",
    "Now it's time to convert the annotations into TFRecord format. On this step we are converting the .xml files to .record\n",
    "\n",
    "The tar command is used to compress a group of files into an archive. \n",
    "\n",
    "* -z : compresses the tar file using gzip\n",
    "* -x : Extracts the archive\n",
    "* -v : Displays verbose information\n",
    "* -f : creates archive with given filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T11:32:46.813289Z",
     "start_time": "2021-09-08T11:32:39.491631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the archive files\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}\n",
    "\n",
    "# Create the TF records\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Update config for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the config file from pretrained model path to the checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:48:14.898326Z",
     "start_time": "2021-09-09T20:48:14.794281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy the pipeline to PRETRAINED_MODEL_NAME\n",
    "# cp src_file dest_directory\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change config file:\n",
    "* Number of classes\n",
    "* Batch Size\n",
    "* Fine Tune Checkpoint\n",
    "* Fine Tune Checkpoint type\n",
    "* Label map path\n",
    "* Annotations path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:49:10.479212Z",
     "start_time": "2021-09-09T20:49:07.695931Z"
    }
   },
   "outputs": [],
   "source": [
    "!python {files['UPDATE_CONFIG_SCRIPT']} -p {files['PIPELINE_CONFIG']} -m {files['LABELMAP']} -t {paths['PRETRAINED_MODEL_PATH']} -n {PRETRAINED_MODEL_NAME} -a {paths['ANNOTATION_PATH']} -c {len(labels)} -b {4}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Model\n",
    "\n",
    "Get the training script and command\n",
    "\n",
    "Inputs of the script model_main_tf2.py: \n",
    "* Model directory - where is the pipeline config \n",
    "* Path to the pipeline config\n",
    "* Number of train steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T20:49:34.877694Z",
     "start_time": "2021-09-09T20:49:34.853742Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, \n",
    "                                                                                             paths['CHECKPOINT_PATH'],\n",
    "                                                                                             files['PIPELINE_CONFIG'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet_v12 --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet_v12\\pipeline.config --num_train_steps=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model\n",
    "\n",
    "Get the command to run the model evaluation\n",
    "\n",
    "Inputs of the script:\n",
    "* Path for the model\n",
    "* File path for the pipeline config\n",
    "* Path for the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:17:34.228225Z",
     "start_time": "2021-09-09T21:17:34.214712Z"
    }
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, \n",
    "                                                                                          paths['CHECKPOINT_PATH'],\n",
    "                                                                                          files['PIPELINE_CONFIG'], \n",
    "                                                                                          paths['CHECKPOINT_PATH'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tensor Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Change to command line code\n",
    "\n",
    "In TensorFlow\\workspace\\models\\my_ssd_mobnet_tuned run the command:\n",
    "\n",
    "tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Freezing the Graph\n",
    "\n",
    "Get command to freeze model... TODO: better explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:15:10.871404Z",
     "start_time": "2021-09-09T21:15:10.856440Z"
    }
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,\n",
    "                                                                                                                                   files['PIPELINE_CONFIG'], \n",
    "                                                                                                                                   paths['CHECKPOINT_PATH'], \n",
    "                                                                                                                         paths['OUTPUT_PATH'])\n",
    "print(command)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the freeze command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Zip the model\n",
    "After train the model in Google Colab, that folder will be extracted on the models folder in the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212.771px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
