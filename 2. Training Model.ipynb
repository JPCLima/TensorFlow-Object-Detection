{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "On this section is focus to create a model to detect the different classes.\n",
    "\n",
    "Steps to create and evaluate the  model: \n",
    "1. Setup  \n",
    "\n",
    "    1.1. Setup Paths  \n",
    "    1.2. Get Pretrained Models  \n",
    "    1.3. Create Label Map  \n",
    "    1.4. Create TensorFlow records  \n",
    "    1.5. Copy Model config to Training Folder  \n",
    "    1.6. Update config for Transfer Learning\n",
    "    \n",
    "    \n",
    "2. Train the Model\n",
    "3. Evaluate the model\n",
    "4. Freezing the Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "* Define the path of the directories and file\n",
    "* Download TF Object Detection\n",
    "* Create label Map\n",
    "* Create TF records\n",
    "* Update config file for the transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup Paths\n",
    "\n",
    "Setting up constants:\n",
    "* Model name\n",
    "* Pretrained Model name\n",
    "* [Pretrained Model url](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n",
    "* TODO: change name of script name\n",
    "* Label map name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:47:31.637639Z",
     "start_time": "2021-08-04T14:47:31.628665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Name\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_v5'\n",
    "\n",
    "# Pretrained model name\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# Define labels\n",
    "labels = ['Cola', 'IceTea', 'Pepsi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting paths: \n",
    "* Workspace\n",
    "* Scripts\n",
    "* API Model Name\n",
    "* Annotation\n",
    "* Image\n",
    "* Model\n",
    "* Pretrained model\n",
    "* Checkpoint\n",
    "* Output\n",
    "* Protoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:47:31.995129Z",
     "start_time": "2021-08-04T14:47:31.973221Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Paths\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),   \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }\n",
    "\n",
    "# Create all the paths from paths dictionary\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Download the TFOD utils\n",
    "\n",
    "Clone the repo TFOD utils. From this repo we will have access to:\n",
    "\n",
    "* Generate tf records\n",
    "* Update config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:47:33.812673Z",
     "start_time": "2021-08-04T14:47:33.799713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define files for the scripts & labelmap\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'generate_tfrecord.py'),\n",
    "    'LABELMAP_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'generate_labelmap.py'), \n",
    "    'UPDATE_CONFIG_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], 'update_config_file.py'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], 'label_map.pbtxt')\n",
    "}\n",
    "\n",
    "# Clone repo for utils\n",
    "if not any(os.scandir(paths['SCRIPTS_PATH'])):\n",
    "    !git clone https://github.com/JPCLima/TFOD-utils {paths['SCRIPTS_PATH']}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Get Pretrained Models\n",
    "\n",
    "* Download the [TensorFlow Model Garden](https://github.com/tensorflow/models) from github\n",
    "* Install Tensorflow Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:47:46.383970Z",
     "start_time": "2021-08-04T14:47:45.377715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get wget to download files\n",
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget\n",
    "\n",
    "# Download models and save them on the APIMODEL_PATH \n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install **TensorFlow Object Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:40:49.301132Z",
     "start_time": "2021-08-04T14:40:02.929141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to verify if all the dependencies are correctly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:42:40.406175Z",
     "start_time": "2021-08-04T14:42:16.906896Z"
    }
   },
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if object detection can be imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T17:27:08.111312Z",
     "start_time": "2021-05-08T17:27:08.097349Z"
    }
   },
   "source": [
    "Install extra dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:41:48.029813Z",
     "start_time": "2021-08-04T14:41:33.786779Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade\n",
    "!pip install PyYAML\n",
    "!pip install pytz\n",
    "!pip install tensorflow-gpu\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:47:50.663760Z",
     "start_time": "2021-08-04T14:47:50.654785Z"
    }
   },
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and import **Pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:48:21.822605Z",
     "start_time": "2021-08-04T14:48:20.316542Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Create Label Map\n",
    "\n",
    "Creating the label map. \n",
    "* The label names must to be the same as the label from the xml file \n",
    "* Each of the classes must to have unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:48:29.888145Z",
     "start_time": "2021-08-04T14:48:29.781049Z"
    }
   },
   "outputs": [],
   "source": [
    "!python {files['LABELMAP_SCRIPT']} -l Cola IceTea Pepsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create TensorFlow records\n",
    "Now it's time to convert the annotations into TFRecord format. On this step we are converting the .xml files to .record\n",
    "\n",
    "The tar command is used to compress a group of files into an archive. \n",
    "\n",
    "* -z : compresses the tar file using gzip\n",
    "* -x : Extracts the archive\n",
    "* -v : Displays verbose information\n",
    "* -f : creates archive with given filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:49:28.397456Z",
     "start_time": "2021-08-04T14:49:20.304461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the archive files\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}\n",
    "\n",
    "# Create the TF records\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Update config for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the config file from pretrained model path to the checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T14:49:34.734608Z",
     "start_time": "2021-08-04T14:49:34.691723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy the pipeline to PRETRAINED_MODEL_NAME\n",
    "# cp src_file dest_directory\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change config file:\n",
    "* Number of classes\n",
    "* Batch Size\n",
    "* Fine Tune Checkpoint\n",
    "* Fine Tune Checkpoint type\n",
    "* Label map path\n",
    "* Annotations path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:19:17.235504Z",
     "start_time": "2021-08-03T19:19:15.230388Z"
    }
   },
   "outputs": [],
   "source": [
    "!python {files['UPDATE_CONFIG_SCRIPT']} -p {files['PIPELINE_CONFIG']} -m {files['LABELMAP']} -t {paths['PRETRAINED_MODEL_PATH']} -n {PRETRAINED_MODEL_NAME} -a {paths['ANNOTATION_PATH']} -c {len(labels)} -b {4}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Model\n",
    "\n",
    "Get the training script and command\n",
    "\n",
    "Inputs of the script model_main_tf2.py: \n",
    "* Model directory - where is the pipeline config \n",
    "* Path to the pipeline config\n",
    "* Number of train steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T13:44:37.099564Z",
     "start_time": "2021-08-03T13:44:37.079617Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=3000\".format(TRAINING_SCRIPT, \n",
    "                                                                                             paths['CHECKPOINT_PATH'],\n",
    "                                                                                             files['PIPELINE_CONFIG'])\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model\n",
    "\n",
    "Get the command to run the model evaluation\n",
    "\n",
    "Inputs of the script:\n",
    "* Path for the model\n",
    "* File path for the pipeline config\n",
    "* Path for the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T12:27:50.987434Z",
     "start_time": "2021-08-03T12:27:50.981400Z"
    }
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, \n",
    "                                                                                          paths['CHECKPOINT_PATH'],\n",
    "                                                                                          files['PIPELINE_CONFIG'], \n",
    "                                                                                          paths['CHECKPOINT_PATH'])\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tensor Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Change to command line code\n",
    "\n",
    "In TensorFlow\\workspace\\models\\my_ssd_mobnet_tuned run the command:\n",
    "\n",
    "tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Freezing the Graph\n",
    "\n",
    "Get command to freeze model... TODO: better explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,\n",
    "                                                                                                                                   files['PIPELINE_CONFIG'], \n",
    "                                                                                                                                   paths['CHECKPOINT_PATH'], \n",
    "print(command)                                                                                                                               paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the freeze command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Zip the model\n",
    "After train the model in Google Colab, that folder will be extracted on the models folder in the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
